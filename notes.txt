Either the chain alist should have a threading option, or that should
be an optional argument to the connector.

----------------

Have the values of chain alist connector and database be whatever the
name is with "-init-proc" appened to it (ugly, but can be changed
later if need be).

The remit of the connector is *all* functionality that's not pure
Scheme, including helper C functions like SQLite3's date-time to and
from text ones.  The database functionality is required to be pure
Scheme, no FFIs whatsoever.

~~~~ This does not allow for using two connectors for the same
database, without renaming the imports.

----------------

What about doing the subprocess approach *without* recourse to a
Scheme's FFI or subprocess facility?  Should not depend on FIFOs or
other POSIX magic, why not have the "subprocess" process exec the
Scheme, thus getting access to its stdin, stdout, and stderror.

----------------

subprocess is functionally equilivent to JDBC as a connector, i.e.:

(db-construct-chain '((connector . (subprocess-init-proc "driver-sqlite"))
                      (database . sqlite3-init-proc)))

Note arguments to a connector turn the value into a list with them
following the connector.

driver-sqlite might be a string, and in sdbi terms the executable
might be named something like "subprocess-sqlite-ffi-driver".

Also brings up an interesting question for that last alist, a bunch of
SQLite3 "quirks" like its data/time handling are implemented as C
functions.  If you're using the subprocess scheme because you're not
exercising your FFI/system interface very much or at all....

In the former case, you might have a choice, SQLite3 functions in
process or in the subprocess.  In the latter, which is more likely,
you'd only support subprocess access to the functions.

----------------

As much as I'd like to dynamically load the right libraries for
whatever's handed to db-chain-construct, at minimum it would require
keeping our own parallel pathname implementation, poorly duplicating
what the Scheme implementation does.  Might as well use the native
library facilities, where the duplication is in your face in the
import at the top of a file.

----------------

parameter-binding-string is probably not an argument to
db-chain-construct, instead an inherant property of a database.

----------------

Logging facilities!

What to be able to log, where and how, and how to let the user
configure this?

Looks like we'll want that syslog style and/or 12 factor app logging
SRFI to do this.  See also the latest SRFI on hooks.

----------------

Data typing through the lifecycle:

Don't use a disjoint type due to all the hassle that brings.  Use a
pair, inspired by timespecs, with:

( information about the type . the current value )

Eventually this becomes:

( a specific database's type . value to be plugged into lowest level api )

The car can be "generic" for general types like a string to go into a
text field.

They can be identified by the car of the pair.  Although, what to put
in there?  Want fast dispatching once the Scheme type is identified.

----------------

Library namespacing:

Only include things that are "always" there; JDBC is not one of them.

(sdbi: obvious

(sdbi connector: partitions namespace under sdbi

(sdbi connector connector-type: will there never be more than one each
net, ffi, or subprocess library??

(sdbi connector ffi sqlite3): the last two are actually always a
distint a pair.  And again, the only one? question.

(sdbi database postgresql): for a database's special sauce that
doesn't change based on the connection method.

What's beyond the named database is up to the library writer, e.g.:

(sdbi database sqlite3 json1) to make that module available.

For our internal use:

(sdbi connector ffi sqlite3)

(sdbi connector subprocess), but also somewhere a net variety to talk
to a different system's database server.  Maybe ideally using its own
wire protocol???

----------------

From: John Cowan <cowan@ccil.org>
Date: Mon, 30 Sep 2019 17:58:49 -0400
Message-ID: <CAD2gp_SUsrcQfxYmz3wkk68bGrR8m6Kpywv7mpDWfkdBikOOJQ@mail.gmail.com>
Subject: Re: Constructing master lists of data types

[...] I found a couple of articles giving the standard data types of
SQL 2011 and 2016.

Strings can be fixed-length, variable-length, or unbounded size (CLOBs).
You can specify a per-column character set and independently a collation
order, but neither the available charsets and collations nor their names
are portable.  There is a concept of NATIONAL CHAR vs plain CHAR types, but
it is not even defined whether these are different encodings, never mind
which encodings they are.

Bytevectors also can be fixed-length, variable-length, or unbounded size
(BLOBs).

Exact numbers can be integers or fixed-point decimal fractions with a
specified precision.  (These may be floats under the covers, as in SQLite).

Inexact numbers can be IEEE binary32 or binary64.

Booleans.

Date/time types are DATE, TIME, and TIMESTAMP.  The last two can have a
precision (fractional seconds).  All three can be with or without offsets
from UTC.  I have a *lot* of opinions about this group.

Time intervals are intervals of time with a start and an end.  They are not
the same as ISO 8601 periods, which are unanchored amounts of time.

Row types are used in SQL programming to represent the type of a single
row.  They can't exist inside a table.

Reference types are pointers to specific rows in specific tables.  Evil,
evil, evil!

Array types are for homogeneous arrays, a hack for getting around first
normal form.  Evil, evil!

Multiset types are another hack for getting around first normal form but
unordered, unlike arrays.  Evil, evil!

Decimal floats (SQL 2016 only).  IEEE, but I have no information on which
of 32-bit, 64-bit, and 128-bit formats are supported.

--------

From: John Cowan <cowan@ccil.org>
Date: Mon, 30 Sep 2019 18:44:41 -0400
Message-ID: <CAD2gp_S0eJQKS6uh4=x+U5RBabe3ncHij6JUoKKXQcp+YxWncw@mail.gmail.com>
Subject: Re: Constructing master lists of data types

Looks like DB2 and Firebase support 64-bit (16-digit) and 28-bit (34-digit)
decfloats.  I found a list of changes in SQL 2016, and that was the only
one relevant to types.

[...]

----------------

"generic-database" as a database type to provide minimal functionality
for databases supported by e.g. JDBC for which no one has written a
specific adapter.

----------------

Need to include mechanisms to dynamically communicate to levels below
sdbi, perhaps MariaDB CONNECT can be told to load a particular CSV
file on the fly.

----------------

MariaDB CONNECT:

https://mariadb.com/kb/en/library/connect/

A general engine to connect non-SQL stuff while you speak SQL to it.

----------------

For database column or whatever type quirks, we need a "don't do
that!" capability to warn or error when a user tries to do something
that will only bring grief.

This will include an optional strict mode for SQLite3.

----------------

Have a "strict" type conversion mode so that e.g. a TIMESTAMP doesn't
get automagically converted into a string?

----------------

Don't forget about star schema and OLAP.

----------------

See how widely SRFI 106 Basic socket interface has been implemented,
it's used by the (postgresql) Snow library.  Chibi Scheme' (chibi net)
hopefully does all the hard work.

----------------

Adopt Perl's influential nomencalture for the low level plumbing:

DBI database interface, what the programmer write to, does not know
query languages.  Does know in some way connection pooling.

DBD database driver, knows its particular database, is where column
types are converted to and from Scheme dynamic types.  Has at least
two layers, that and below it which is what talks to the database.

----------------

The stack:

  user code
  -
  maybe a framework
  -
  user-friendly procedures like in the PostgreSQL egg
  -
  DBI, knows interaction patterns e.g. connect, operations, transactions
  -
  DBD data mapper knows about the particular database's data types
  -
  DBD database interface knows the Scheme and interfacing to particular database
  -
  There might be a layer here to fan out to different connection methods
  -
  What John and Lassi are working on, or FFI, wire protocol, whatever
  -
  Database

----------------

Rough sketch of DBI API, prior to megering with John Cowan's Simple SQL API:

(db-connect config [anti-injection-proc]) -> db

(db-disconnect db)

(db-execute

execute needs a general optional? config argument so the programmer
can for example direct that it be prepared, or not, depending on the
default.

(db-cursor-magic

executing literal strings should be handled by a "config" arg to db-execute

how and where to pass through type conversion information for DBD top layer?

Need general, generic pass throughs from DBI to both layers of the DBD.

Include plugable connection pooling facility.

Lassi: Is there value in altering the timeout while a connection is
open? It would probably be more portable if the timeout is given once
as an option to "open-sql-database". But if it's common to keep
changing the timeout it may make sense to have this as well.

----

Errors:

John, in response to my noting the "ORA-" prefix was particularly useful.

It would be good to have a particular symbol naming each DB engine:
oracle, postgresql, mysql, sqlite, etc. And that symbol would be tossed
around in a lot of places, so library code could find out which DB it is
using.

It might be good to make the error an alist:

((engine sqlite)
  (native-error-symbol SQLITE_BUSY)
  (native-error-code-integer 5)
  (native-error-message "database is locked")
  ...any other fields...)

Obviously pick better names :)

The DB driver could return as much data as it knows with each error.
Callers can ignore the data they don't understand.

----

Type mapping regime:

Hierarchy of type mappers, the first match going down wins:

  User specified (perhaps even user supplied)
  -
  DBD database type layer supplied
  -
  standard in DBI

TBD is how these mappers interact with the lowest level

----

transactions

Example from Peter Bex, modified with a rollback procedure that does
the proper exception or continuation magic under the table:

(with-transaction db
  (lambda ()
    (query db "INSERT INTO foo (bar, qux) VALUES (1, 2)")

    (with-transaction
      (lambda ()
        (query db "INSERT INTO foo (bar, qux) VALUES (3, 4)")
        ;; Oops, decide to roll this back
        (rollback)))

    (query db "INSERT INTO foo (bar, qux) VALUES (5, 6)")))

Rolling back two or more savepoint levels is probably worse than a
80/20 case.

----

Lassi on connection parameters for opening database connections:

I'd make it (open-sql-database ...) where ... is a plist of arbitrary
key-value pairs. For example, I just implemented Postgres connect
using its C library, and it accepts tons of options like that.

[ Since then it looks like alists are better. ]

The simplicity of a single "connection string" is enticing, but the real
world is not that simple. Postgres has some legacy support to parse such
a connection string, but I haven't dared look into what kinds of
shenanigans go into it :)

For a "connection string" I'd go with a DATABASE_URL environment
variable as endorsed by 12factor. Our DB API doesn't have to worry about
that; we can give key-value pairs to the DB and the DATABASE_URL library
decomposes URLs into those pairs. I wrote such a parser for Racket:
<https://github.com/lassik/racket-database-url/blob/master/database-url.rkt>.

The database URL syntax is an unruly wild west, but other kinds of
connection strings are probably worse...

----------------

Cassandra and Neo4j both have their own query languages in the general
mold of SQL.

Cassandra from Wikipedia, CQL 3.0:

CREATE KEYSPACE MyKeySpace
  WITH REPLICATION = { 'class' : 'SimpleStrategy', 'replication_factor' : 3 };

USE MyKeySpace;

CREATE COLUMNFAMILY MyColumns (id text, Last text, First text, PRIMARY KEY(id));

INSERT INTO MyColumns (id, Last, First) VALUES ('1', 'Doe', 'John');

SELECT * FROM MyColumns;

Cassandra has a C/C++ library, https://github.com/datastax/cpp-driver

----------------

See also PostGIS using https://en.wikipedia.org/wiki/Simple_Features
and extensions

----------------

From: John Cowan <cowan@ccil.org>
Date: Fri, 27 Sep 2019 11:13:27 -0400
Message-ID: <CAD2gp_T25VmzdFWZoSkq9vJWFdwR8FRDmLsq8NJUmBuW=xZL_w@mail.gmail.com>
Subject: Rectangularity run wild: the MariaDB storage engine CONNECT

Since MariaDB's over the wire protocol is backward compatible with MySQL,
it is part of our first-class support set.  And Maria (but not My) has a
hidden treasure we can exploit: the CONNECT storage engine.  This is
basically an engine for talking to sources of data other than classical
base tables, such as are supported by MyISAM, Aria, InnoDB, etc.  Here are
the sources it currently supports and rectangularizes:

Fixed-length binary records
CSV and friends
dBase III/IV files (FoxBase etc.)
Flat text files
Filesystem directories (either hierarchical or non-hierarchical view)
INI files
JDBC
JSON files (if the data is reasonably rectangular)
MongoDB
ODBC (including unixODBC)
Column-oriented binary with one file per column (alpha)
XML (if the data is reasonably rectangular)
HTML tables
Zipfile directories

In some cases you have to use a CREATE TABLE to specify the
rectangularization, in other cases not.  Some are updatable directly;
others are updatable but destroy the original (updating XML gives something
matching the rectangular view, not the original more complex view), yet
others are read-only.  See
<https://mariadb.com/kb/en/library/connect-table-types-overview/> for links
to more detailed docs.

There are also engines outside CONNECT that provide similar abilities:
Cassandra, MyRocks, Object Query Graph.  See
<https://mariadb.com/kb/en/library/storage-engines/> for links.

----------------

From: John Cowan <cowan@ccil.org>
Date: Mon, 30 Sep 2019 16:25:04 -0400
Message-ID: <CAD2gp_S5a5Rwqe0vju=NOD81b8YU+sZeKCPabbcJu9YSvfzeJQ@mail.gmail.com>
Subject: Re: sdbi design in detail and MariaDB CONNECT

On Mon, Sep 30, 2019 at 12:28 PM Lassi Kortela <lassi@lassi.io> wrote:\

[...]

> Again if I understood John correctly, CONNECT takes normal SQL queries
> and returns normal SQL results,

More precisely, Connect allows you to say things like CREATE TABLE people
ENGINE=connect TABLE_TYPE=csv FILE_NAME=people.csv.  Then the people table
looks like an ordinary Maria table in the current database, and you can do
ordinary SQL operations, including joining it with native tables or other
Connect tables.  The people.csv file may or may not be cached inside
Maria.  This is the same idea as SQLite virtual tables, though AFAIK there
are no SQLite drivers available for external DBMSes, only for files,
directories, etc.  (It's a pity that Connect does not support SQLite
directly; it really should, though SQLite is accessible via Connect's ODBC
table type.)

In the JDBC case, we'd use CREATE TABLE people ENGINE=connect
TABLE_TYPE=jdbc connection='jdbc:postgresql://host/mtr' dbname=public
tabname=people option_list='User=mtr,Password=mtr' to connect to a
PostgreSQL server on host.

If the foreign table already exists, the Maria table is essentially a view
over it.  However, it is also possible to CREATE TABLE when no foreign
table exists, in which case it will be created (modulo permissions) and in
that case you have to specify the column names, types, keys, indexes, etc.
as you would for a native table.

----------------

Package: dbconfig-common
Architecture: all
Version: 2.0.9
Priority: optional
Section: admin
Origin: Ubuntu
Maintainer: Ubuntu Developers <ubuntu-devel-discuss@lists.ubuntu.com>
Original-Maintainer: Paul Gevers <elbrus@debian.org>
Bugs: https://bugs.launchpad.net/ubuntu/+filebug
Installed-Size: 1545
Depends: ucf, debconf (>= 0.5) | debconf-2.0
Suggests: dbconfig-mysql | dbconfig-pgsql | dbconfig-sqlite | dbconfig-sqlite3 | dbconfig-no-thanks
Breaks: bandwidthd-pgsql (<< 2.0.1+cvs20090917-9~)
Filename: pool/main/d/dbconfig-common/dbconfig-common_2.0.9_all.deb
Size: 600950
MD5sum: a667111a3db0147f35b9b63de8cb8b32
SHA1: db9e903b22d1d3f5904e3cf7d93ab25de3e35a21
SHA256: 97abe87d724b2ca011d745b5fb95b87b226f2ac10fd6d9d6312c938ff562e6ef
Description-en: framework that helps packages to manage databases
 This package contains the core of the dbconfig-common framework. This
 framework presents a policy and implementation for managing various databases
 used by applications included in Debian packages.
 .
 It can:
  - support MySQL/MariaDB, PostgreSQL, and SQLite based applications;
  - create or remove databases and database users;
  - access local or remote databases;
  - upgrade/modify databases when upstream changes database structure;
  - generate config files in many formats with the database info;
  - import configs from packages previously managing databases on their own;
  - prompt users with a set of normalized, pre-translated questions;
  - handle failures gracefully, with an option to retry;
  - do all the hard work automatically;
  - work for package maintainers with little effort on their part;
  - work for local admins with little effort on their part;
  - comply with an agreed upon set of standards for behavior;
  - do absolutely nothing if that is the whim of the local admin;
  - perform all operations from within the standard flow of
    package management (no additional skill is required of the local
    admin).
Description-md5: 3fa1997ed54b15c65dd46db7b40eb2f0
Supported: 5y

dbconfig-mysql - dbconfig-common MySQL/MariaDB support
dbconfig-no-thanks - dbconfig-common bypass
dbconfig-pgsql - dbconfig-common PostgreSQL support
dbconfig-sqlite3 - dbconfig-common SQLite3 support
dbconfig-sqlite - dbconfig-common SQLite support

--------

It's reported that SISC had a JDBC interface.

--------

User libraries/SRFIs that the Schemepersist stack below will support:

A Scheme version of Clojure's Korma???
